\documentclass[11pt,a4paper]{scrartcl}
\usepackage[top=3cm,bottom=3cm,left=2cm,right=2cm]{geometry} % Seitenränder einstellen
\usepackage[utf8]{inputenc} % Umlaute im Text
\usepackage[english]{babel} % Worttrennung nach der neuen Rechtschreibung und deutsche Bezeichnungen
\usepackage[dvipsnames]{xcolor} % Farbe in Dokument
\parindent 0pt % kein Einrücken bei neuem Absatz
\usepackage{amsmath} % zusätzliche mathematische Umgebungen
\usepackage{amssymb} % zusätzliche mathematische Symbole
%\usepackage{bbold} % zusätzliche mathematische Symbole
\usepackage{units} % schöne Einheiten und Brüche
\usepackage{icomma} % kein Leerzeichen bei 1,23 in Mathe-Umgebung
\usepackage{wrapfig} % von Schrift umflossene Bilder und Tabellen
\usepackage{picinpar} % Objekt in Fließtext platzieren (ähnlich zu wrapfig)
\usepackage{scrhack} % verbessert andere Pakete, bessere Interaktion mit KOMA-Skript
\usepackage{float} % bessere Anpassung von Fließobjekten
\usepackage{pgf} % Makro zur Erstellung von Graphiken
\usepackage{tikz} % Benutzeroberfläche für pgf
\usepackage[margin=10pt,font=small,labelfont=bf,labelsep=endash,format=plain]{caption} % Einstellungen für Tabellen und Bildunterschriften
\usepackage{listings}
\usepackage{subcaption} % Unterschriften für mehrere Bilder
\usepackage{enumitem} % no indentation at description environment
\usepackage[onehalfspacing]{setspace} % Änderung des Zeilenabstandes (hier: 1,5-fach)
\usepackage{booktabs} % Einstellungen für schönere Tabellen
\usepackage{graphicx} % Einfügen von Grafiken -> wird in master-file geladen
\usepackage{url} % URL's (z.B. in Literatur) schöner formatieren
\usepackage[pdftex]{hyperref} % Verweise innerhalb und nach außerhalb des PDF; hyperref immer als letztes Paket einbinden

% define bordermatrix with brackets

\makeatletter
\def\bbordermatrix#1{\begingroup \m@th
  \@tempdima 4.75\p@
  \setbox\z@\vbox{%
    \def\cr{\crcr\noalign{\kern2\p@\global\let\cr\endline}}%
    \ialign{$##$\hfil\kern2\p@\kern\@tempdima&\thinspace\hfil$##$\hfil
      &&\quad\hfil$##$\hfil\crcr
      \omit\strut\hfil\crcr\noalign{\kern-\baselineskip}%
      #1\crcr\omit\strut\cr}}%
  \setbox\tw@\vbox{\unvcopy\z@\global\setbox\@ne\lastbox}%
  \setbox\tw@\hbox{\unhbox\@ne\unskip\global\setbox\@ne\lastbox}%
  \setbox\tw@\hbox{$\kern\wd\@ne\kern-\@tempdima\left[\kern-\wd\@ne
    \global\setbox\@ne\vbox{\box\@ne\kern2\p@}%
    \vcenter{\kern-\ht\@ne\unvbox\z@\kern-\baselineskip}\,\right]$}%
  \null\;\vbox{\kern\ht\@ne\box\tw@}\endgroup}
\makeatother

% make Titel
\title{Mining massive Datasets WS 2017/18}
\subtitle{Problem Set 3}
\author{Rudolf Chrispens, Marvin, Daniela Schacherer}

\begin{document}

\maketitle

\section*{Exercise 01}
\begin{itemize}
\item[1.] More information in Ex1.py.
	Implemented the peusdocode into a working .py algorithm.
	Could not increase the performance of the for loop. Couldn't understand how this would be done?
\item[2.] 
	Solution for problemset "dataset-problemset3-ex1-2" can be found in 1\_2\_ProblemsetSolution.pdf the code
	used code was in Ex1.py. 
	\begin{lstlisting}
		numpyDataset = np.load("dataset-problemset3-ex1-2.npy")
		print(numpyDataset)
	\end{lstlisting}
\item[3.] Code is in  Ex1\_3.py. Time is recorded in seconds.
\begin{verbatim}	
	Time: 	1.5244791507720947	N: 1
	Time: 	1.0207879543304443	N: 2
	Time: 	1.9531109333038330	N: 3
	Time: 	3.8049488067626953	N: 4
	Time: 	5.6916959285736080	N: 5
	Time: 	9.2186932563781740	N: 6
	Time: 	14.890535116195679	N: 7
	Time: 	22.376883983612060	N: 8
	Time: 	29.547118186950684	N: 9
	Time: 	44.000823020935060	N: 10
	Time: 	66.097368001937870	N: 11
	Time: 	73.463916063308720	N: 12
	Time: 	95.624380350112920	N: 13
	Time: 	122.46513080596924	N: 14
	Time: 	153.88598299026490	N: 15
	Time: 	191.58319568634033	N: 16
	Time: 	235.73992490768433	N: 17
	Time: 	286.40261006355286	N: 18
	Time: 	347.29994392395020	N: 19
\end{verbatim}
\end{itemize}

\section*{Exercise 02}
	\begin{itemize}
		\item[1.] MapReduce Pseudocode for k-means\\
		The k-means algorithm consists of two steps. The first step computes for each mean $\mu_i$ the set of points that are closest to it. In the second step new means are computed using the priorily determined sets. These two phases correspond to the Map- and the Reduce phase of MapReduce. \\
The Map phase computes the squared distance to all means for each point $x$ in the dataset and returns a key-value pair $(i, (x,1))$ where $i$ is the index of the mean with the smallest distance to point $x$. The Reduce phase then simply computes the sum of the vector points for each key. \\
Pseudocode:
\begin{itemize}
	\item \textbf{Map} for every point x: return $(argmin_i(|| x- \mu_i ||, (x,1))$
	\item \textbf{Reduce} for every elements with key $i$: return $(i, (x+y, s+t))$ with x and y being the data points and s and t being the counts.
\end{itemize}

		\item[2.] MapReduce Pseudocode for Inverted Indexing\\
		Inverted 
		\begin{itemize}
			\item \textbf{Map}: for every keyword in the given list the Mapper should perform the following: \\
		if $keyword$ in $text_i$: return $(keyword, doc_i)$
			\item \textbf{Reduce}: for every keyword add the documents indices to a list and finally return $(keyword, [doc_i, doc_j, ..])$
		\end{itemize}
		The proposed pseudocode would probably not scale well with the number of keywords, because the mapper has to run a search algorithm for every keyword. If the number of mappers is limited, a mapper has to perform multiple searches and thus the time for the complete calculation will get larger. 


		\item[3.] MapReduce Pseudocode \\
		When one dataset is small and every mapper has access to it the joining can already be part of the mapping phase. Let $R$ with tuples $(a,b)$ and $S$ with tuples $(b,c)$ be the datasets, and $R$ is the smaller one. We want to join on $b$. Every mapper gets tuples from $S$ in this form: $(S,a,b)$
		\begin{itemize}
			\item \textbf{Map}: for every tuple of R: \\
			if $b$ in $(S,a,b)$: return $(a,b,c)$
			\item \textbf{Reduce}: in the reduce phase we now only have to collect all the joined tuples. 
		\end{itemize}



	\end{itemize}
	
	
\section*{Exercise 03}

\subsection*{a)}

In Spark the input of every Transformation (map) and Action (reduce) is a RDD. With a Transformation the output is again a RDD and with an action the output can have different types. The data in the RDD can be different, key-value pairs is not mandatory.\\
In MapReduce the output is not a RDD but a set of key-value pairs. The output is again a set of key-value pairs. Depending on the map step the output has a different number of data. At the reduce step it is basically the same. Input and output are both key-value pairs. 

\subsection*{b)}

I wrote a spark application that counts the number of characters in a textfile. The Code is in the submitted \textit{ex3problem3b.py} file that uses the textfile \textit{lorem\_ipsum.txt}.\\\\
Program code:
\lstset{breaklines=true}
\begin{lstlisting}
from pyspark import SparkContext

if __name__ == "__main__":
    sc = SparkContext(appName="PythonKMeans")

    lines = sc.textFile("lorem_ipsum.txt")
    lineLengths = lines.map(lambda s: len(s))
    totalLength = lineLengths.reduce(lambda a, b: a + b)

    print(totalLength)

    sc.stop()
\end{lstlisting}

The output of the Program

\begin{lstlisting}
591
\end{lstlisting}

\subsection*{c)}

Here is the Spark reduce function I try to show in MapReduce:

\begin{lstlisting}
exampleRdd.reduce(lambda a, b: a**2 + b**2)
\end{lstlisting}

In MapReduce it would be something like that (I guess):

\begin{lstlisting}
numbers.map(x => x * x)
numbers.reduce(_ + _)
\end{lstlisting}


\section*{Exercise 04}

\subsection*{a)}

Let \textit{m} be the size of the matrix and \textit{v} the size of the vector. Both gets divided in \textit{n} different parts. Each map-task gets \textit{m/n} and \textit{v/n} parts and this \textit{n} times to multiply all of the matrix. Because of that we get a communication cost of $O(n * (m/n + v/n))$.

\subsection*{b)}

Let $n$ be the number of tuples. Then the answer is just $O(n)$ because the only input are the tuples.

\end{document}

